{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/Proga/object detection part two/image_dataset/test_0.xml', 'D:/Proga/object detection part two/image_dataset/test_1.xml', 'D:/Proga/object detection part two/image_dataset/test_10.xml', 'D:/Proga/object detection part two/image_dataset/test_100.xml', 'D:/Proga/object detection part two/image_dataset/test_101.xml']\n"
     ]
    }
   ],
   "source": [
    "#преобразуем папку в tfrecord\n",
    "#так чтение датасета и обучение будет быстрее\n",
    "\n",
    "fn = \"D:/Proga/object detection part two/image_dataset\"\n",
    "#формируем список всех xml файлов в папке\n",
    "p = [fn + '/' + f for f in listdir(fn) if isfile(join(fn, f)) and f[-1] == 'l'] \n",
    "print(p[:5])\n",
    "\n",
    "    \n",
    "def load_img(img):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)/256\n",
    "    img = tf.image.resize(img,(128,128))\n",
    "    return img\n",
    "    \n",
    "#создаем запись\n",
    "writer = tf.io.TFRecordWriter('D:/Proga/object detection part two/bounding_box_dataset.tfrecord')\n",
    "\n",
    "\n",
    "\n",
    "for xml in p:\n",
    "    tree = ET.parse(xml) #адрес файла\n",
    "    root=tree.getroot()   #парсим\n",
    "    num_objects = len(root)-6\n",
    "    cords = []\n",
    "    w = int(root[4][0].text) #ширина x\n",
    "    h = int(root[4][1].text) #высота y\n",
    "    for num in range(num_objects):\n",
    "        object_cords = []\n",
    "        #нормализуем координаты от -1 до 1, опираясь на исходные координаты\n",
    "        object_cords.append(int(root[num+6][4][0].text)/w*2-1)\n",
    "        object_cords.append(int(root[num+6][4][1].text)/h*2-1)\n",
    "        object_cords.append(int(root[num+6][4][2].text)/w*2-1)\n",
    "        object_cords.append(int(root[num+6][4][3].text)/h*2-1)\n",
    "        cords.append(object_cords)\n",
    "\n",
    "    img = load_img(root[2].text)\n",
    "    #готовим данные, представляем в байтовом виде\n",
    "    serialized_img = tf.io.serialize_tensor(img).numpy()\n",
    "    serialized_cords = tf.io.serialize_tensor(cords).numpy()\n",
    "    #собираем экзепмляр\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_img])),\n",
    "        'cords': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_cords]))\n",
    "    }))\n",
    "\n",
    "    #записываем в запись\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset('D:/Proga/object detection part two/bounding_box_dataset.tfrecord')\n",
    "\n",
    "\n",
    "def parse_record(record):\n",
    "    #нужно описать приходящий экземпляр\n",
    "    #имена элементов как при записи\n",
    "    feature_description = {\n",
    "        'img': tf.io.FixedLenFeature([], tf.string),\n",
    "        'cords': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    parsed_record = tf.io.parse_single_example(record, feature_description)\n",
    "    img = tf.io.parse_tensor(parsed_record['img'], out_type=tf.float32)\n",
    "    cords = tf.io.parse_tensor(parsed_record['cords'], out_type=tf.float32)\n",
    "    return img, cords\n",
    "\n",
    "#пройдемся по записи и распакуем ее\n",
    "dataset = dataset.map(parse_record)\n",
    "\n",
    "#что-нибудь выведем\n",
    "for i, c in dataset.take(1):\n",
    "    print(i.shape)\n",
    "    print(c.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
