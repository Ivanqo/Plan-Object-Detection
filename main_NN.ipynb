{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем разное\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузим модели\n",
    "localizator = tf.keras.models.load_model('D:/Proga/object detection part two/my_bb_model.keras')\n",
    "classifier = tf.keras.models.load_model('D:/Proga/object detection part two/my_classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция работы с нейросетями: подготовка изображения, детекция\n",
    "#на выходе три массива: координаты (10,4) , классы (10) , вероятности (10)\n",
    "\n",
    "def Detect_objects(image):\n",
    "    #подготовка картинки\n",
    "    image = tf.cast(image, dtype = tf.float32) / 256\n",
    "    small_image = tf.image.resize(image, (512, 512))\n",
    "    big_image = tf.image.resize(image, (1024, 1024))\n",
    "    image_exp = tf.expand_dims(small_image, axis = 0)\n",
    "    \n",
    "    #локализация\n",
    "    bb_cords = localizator(image_exp)\n",
    "    bb_cords = tf.squeeze(bb_cords, axis = 0)\n",
    "    \n",
    "    #нормализация по размеру картинки\n",
    "    bb_cords = (bb_cords+1)/2*512\n",
    "    bb_cords = tf.reshape(bb_cords, [10, 3])\n",
    "    \n",
    "    #разделяем на элементы\n",
    "    fxmin, ymin, fxmax = tf.split(bb_cords, 3, axis = 1)\n",
    "    \n",
    "    #нормализуем\n",
    "    xmin = tf.minimum(fxmin, fxmax)\n",
    "    xmax = tf.maximum(fxmin, fxmax)\n",
    "    \n",
    "    xmin = tf.clip_by_value(xmin, 0, 512)\n",
    "    ymin = tf.clip_by_value(ymin, 0, 512)\n",
    "    \n",
    "    size = xmax - xmin\n",
    "    \n",
    "    #сумма координаты и размера должны быть <= 128\n",
    "    xsize = tf.clip_by_value(size, 1, 512 - xmin)\n",
    "    ysize = tf.clip_by_value(size, 1, 512 - ymin)\n",
    "    \n",
    "    #нарезаем и собираем в массив (10, 32, 32, 3)\n",
    "    ymin*= 8\n",
    "    xmin*= 8\n",
    "    ysize*= 8\n",
    "    xsize*= 8\n",
    "    for n in range(10):\n",
    "        ii = tf.image.crop_to_bounding_box(big_image, int(ymin[n][0]), int(xmin[n][0]), int(ysize[n][0]), int(xsize[n][0]))\n",
    "        ii = tf.image.resize(ii, (512,512))\n",
    "        ii = tf.expand_dims(ii, axis = 0)\n",
    "        if n == 0:\n",
    "            cropped = ii \n",
    "        else:\n",
    "            cropped = tf.concat([cropped, ii], axis = 0)\n",
    "    \n",
    "    #классифицируем\n",
    "    probs = classifier(cropped)\n",
    "    \n",
    "    probs = probs.numpy()\n",
    "    \n",
    "    #считаем метки класса (индекс наибольшего среди вероятностей)\n",
    "    ma = np.amax(probs, axis = 1)\n",
    "    ma = np.expand_dims(ma, axis = 1)\n",
    "    _, classes = np.where(probs == ma)\n",
    "    \n",
    "    #берем ту вероятность, которая наибольшая\n",
    "    res_probs = []\n",
    "    for a in range(10):\n",
    "        res_probs.append(probs[a][classes[a]])\n",
    "    \n",
    "    #собираем координаты в нормальный вид\n",
    "    cords = tf.concat([xmin/8, ymin/8, xmin/8+xsize/8, ymin/8+ysize/8], axis = 1)\n",
    "    cords = cords.numpy()\n",
    "\n",
    "    \n",
    "    return cords, classes, res_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#th - вероятность, ниже которой рамки не отображаются\n",
    "namespace = {0: 'NOTHING', 1: 'OSI' }\n",
    "\n",
    "def visualize(in_image, cords, classes, probs, th = 0.8):\n",
    "    big_image = tf.image.resize(in_image, (1024,1024)).numpy() / 256\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 1\n",
    "    thickness = 2\n",
    "\n",
    "    for i in range(len(cords)):\n",
    "        if classes[i]!= 0 and probs[i] >= th:\n",
    "            #введем цвета для всех обьектов\n",
    "            if classes[i] == 1:\n",
    "                color = (1, 0, 0)\n",
    "            if classes[i] == 2:\n",
    "                color = (0, 1, 0)\n",
    "            text = namespace[classes[i]] + ' ' + str(probs[i]*100) + '%'\n",
    "            \n",
    "            org = ((int(cords[i][0])*8,  int(cords[i][1])*8-10))\n",
    "            #рисуем текст и квадраты\n",
    "            big_image = cv2.putText(big_image, text, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            big_image = cv2.rectangle(big_image ,(int(cords[i][0])*8, int(cords[i][1])*8),(int(cords[i][2])*8,int(cords[i][3])*8),color,5)\n",
    "            \n",
    "        \n",
    "    \n",
    "    return big_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция обьединяет две рамки одного класса в одну, если они пересекаются\n",
    "#tau - порог IoU этих рамок чтобы их обьединить (0.1 - все подряд, 0.9 - только очень близкие)\n",
    "#функцию можно применять несколько раз, результат улучшится\n",
    "\n",
    "def prettify(cords, classes, probs, tau = 0.2):\n",
    "    newcords = []\n",
    "    newclasses = []\n",
    "    newprobs = []\n",
    "    \n",
    "    for i1 in range(len(classes)):\n",
    "        \n",
    "        if classes[i1]!=0:\n",
    "            found = False\n",
    "            for i2 in range(len(classes)):\n",
    "                if classes[i2]!=0 and  i1 != i2:\n",
    "                    \n",
    "                    #вычислим IoU - самый надежный способ определить совпадение\n",
    "                    x_overlap = max(0, min(cords[i1][2], cords[i2][2]) - max(cords[i1][0], cords[i2][0]))\n",
    "                    y_overlap = max(0, min(cords[i1][3], cords[i2][3]) - max(cords[i1][1], cords[i2][1]))\n",
    "                    inter = x_overlap*y_overlap\n",
    "                    area1 = (cords[i1][2] - cords[i1][0])*(cords[i1][3] - cords[i1][1])\n",
    "                    area2 = (cords[i2][2] - cords[i2][0])*(cords[i2][3] - cords[i2][1])\n",
    "                    union = area1+area2 - inter\n",
    "                    IoU = inter/union\n",
    "                    if IoU > tau:\n",
    "                        \n",
    "                        #считаем среднее по всем координатам между двух рамок\n",
    "                        newcord = [(cords[i1][0]+ cords[i2][0])//2,(cords[i1][1]+ cords[i2][1])//2,(cords[i1][2]+ cords[i2][2])//2,(cords[i1][3]+ cords[i2][3])//2]\n",
    "                        newcords.append(newcord)\n",
    "\n",
    "                        newclasses.append(classes[i1])\n",
    "                        newprobs.append(probs[i1])\n",
    "                        \n",
    "                        #обнуляем класс, чтобы больше не крутить эту рамку\n",
    "                        classes[i1] = 0\n",
    "                        classes[i2] = 0\n",
    "                        found = True\n",
    "                        \n",
    "            #если ни с чем не обьединили, так и оставляем\n",
    "            if found == False:\n",
    "                newcords.append(cords[i1])\n",
    "                newclasses.append(classes[i1])\n",
    "                newprobs.append(probs[i1])\n",
    "            \n",
    "            \n",
    "                        \n",
    "    return newcords, newclasses, newprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#разделение изображения\n",
    "input_image = Image.open(\"D:/Proga/object detection part two/1.png\")\n",
    "\n",
    "# The size of each tile (in pixels)\n",
    "tile_width = 256\n",
    "tile_height = 256\n",
    "\n",
    "# Get the dimensions of the input image\n",
    "image_width, image_height = input_image.size\n",
    "\n",
    "# Loop through the image and split it into tiles\n",
    "for x in range(0, image_width, tile_width):\n",
    "    for y in range(0, image_height, tile_height):\n",
    "        left = x\n",
    "        upper = y\n",
    "        right = x + tile_width\n",
    "        lower = y + tile_height\n",
    "\n",
    "        # Crop the tile from the original image\n",
    "        tile = input_image.crop((left, upper, right, lower))\n",
    "\n",
    "        # Save the tile as a separate image\n",
    "        tile.save(f'D:/Proga/object detection part two/separate/tile_{x}_{y}.png')\n",
    "# Close the input image\n",
    "input_image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"D:/Proga/object detection part two/separate\"\n",
    "p = [fn + '/' + f for f in listdir(fn) if isfile(join(fn, f)) and f[-1] == 'g'] \n",
    "\n",
    "for png in p:\n",
    "    image = cv2.imread(png.replace('\\\\','/'))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    cords, classes, probs = Detect_objects(image)\n",
    "    for i in range(1):\n",
    "        cords, classes, probs = prettify(cords, classes, probs, 0.1)\n",
    "    result = visualize(image, cords, classes, probs, 0.5)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "width must be >= target + offset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/Proga/object detection part two/1.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m----> 3\u001b[0m cords, classes, probs \u001b[38;5;241m=\u001b[39m \u001b[43mDetect_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      5\u001b[0m     cords, classes, probs \u001b[38;5;241m=\u001b[39m prettify(cords, classes, probs, \u001b[38;5;241m0.1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 41\u001b[0m, in \u001b[0;36mDetect_objects\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     39\u001b[0m xsize\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 41\u001b[0m     ii \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop_to_bounding_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbig_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mymin\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxmin\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mysize\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxsize\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     ii \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(ii, (\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m512\u001b[39m))\n\u001b[0;32m     43\u001b[0m     ii \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(ii, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:90\u001b[0m, in \u001b[0;36m_assert\u001b[1;34m(cond, ex_type, msg)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cond:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex_type(msg)\n\u001b[0;32m     91\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[1;31mValueError\u001b[0m: width must be >= target + offset."
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"D:/Proga/object detection part two/1.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cords, classes, probs = Detect_objects(image)\n",
    "for i in range(1):\n",
    "    cords, classes, probs = prettify(cords, classes, probs, 0.1)\n",
    "result = visualize(image, cords, classes, probs, 0.5)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "#удаление нарезанных частей из изображения\n",
    "folder = 'D:/Proga/MachineVisionForBuilding/testing_image/separate'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "        os.unlink(file_path)\n",
    "    elif os.path.isdir(file_path):\n",
    "        shutil.rmtree(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
